{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf24655-2a6a-4144-a281-bb9720474f57",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Shallow Water Bathymetry With ICESat-2\n",
    "\n",
    "Tutorial led by Jonathan Markel at the 2023 ICESat-2 Hackweek.\n",
    "\n",
    "## Learning Objectives\n",
    "- Learn what ICESat-2 bathymetry looks like, where to find it, and how to visualize it\n",
    "- Understand pros / cons of different signal finding approachs for bathymetry\n",
    "- Extract water surface and seafloor returns from the photon data\n",
    "- Apply corrections to photon depths for laser refraction\n",
    "\n",
    "## Prerequisites\n",
    "- EarthData Account\n",
    "- [SlideRule](https://slideruleearth.io/web/)\n",
    "- ATL03 photon heights (See User Guide available [here](https://nsidc.org/data/atl03/versions/6) via NSIDC)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "ICESat-2 is a spaceborne laser altimeter launched by NASA in 2018 to collect ice sheet, cloud, and land elevation data. It has also demonstrated the ability to collect shallow water depths, AKA 'bathymetry', in many coastal locations around the world. Until the release of [ATL24](https://ui.adsabs.harvard.edu/abs/2022AGUFM.C35D0907M/abstract) simplifies the task of analyzing ICESat-2 derived depth data for most users, some may be interested in using the ATL03 data to analyze their own area of interest. Several different methods have been developed in the literature for classifying bathymetry photons, including [density-based](), [histogram-based](), and other approaches, often requiring some level of manual intervention to acount for different shallow water environments.\n",
    "\n",
    "This tutorial aims to develop the basic Python data access, analysis, and visualization techniques for anyone to get started using ICESat-2 for shallow water bathymetry around the world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b057557-eef6-4c2d-abb9-a72b9a87f16e",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Let's import the Python packages needed for this tutorial and initialize Sliderule for downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0bca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import shapely\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "from sliderule import sliderule, icesat2, earthdata\n",
    "\n",
    "import ipyleaflet\n",
    "from datetime import datetime, timedelta\n",
    "from shapely import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d96296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"slideruleearth.io\"\n",
    "icesat2.init(url, verbose=False)\n",
    "asset = \"icesat2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78255766-14c1-4074-9609-814bc8bfe569",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Define Study Site\n",
    "\n",
    "For the purposes of this demo, we'll use OpenAltimetry to identify an ICESat-2 track with good bathymetric signal for analysis.\n",
    "1. Go to [OpenAltimetry's ICESat-2 Webpage](https://openaltimetry.org/data/icesat2/), and navigate to your general area of interest.\n",
    "2. Select a ground track / date, try a few dates to see how the ground track / signal varies between satellite overpasses.\n",
    "3. Use the ATL08 preview (default) to identify tracks that are likely to have a good signal. A track with good signal will have dense, regularly space points appear over the satelite ground track.\n",
    "4. Draw a bounding box using the 'Select a Region' button in the top right. Click on this box and 'View Signal Photons'.\n",
    "5. Let's make sure we're actually looking at the photon data we're interested in. Select 'View All Data' (available for small to medium sized AOIs) to ensure all photons are plotted. Without this step bathymetry signal is often hidden by its relatively low density. You may also need to adjust which signal photons are plotted using the buttons below the figure.\n",
    "6. If the track contains good bathymetric signal, note the date and track ID (repeat ground track number) below.\n",
    "\n",
    "Alternatively, one of several areas of interest can be selected by modifying the 'aoi_name' variable in the next cell, just in case there are issues accessing EarthData or finding data in OpenAltimetry during the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696bdbe-a415-4f4f-a4de-0102c9197199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modify the following lines for custom tracks identified from Open Altimetry\n",
    "\n",
    "target_date = '' #'YYYY-MM-DD'\n",
    "target_rgt = 0 # track ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079d2c7-ff82-414b-82aa-ce598ef0eaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set aoi_name to user defined if date/rgt specified using OpenAltimetry\n",
    "\n",
    "aoi_name = 'japan' # options: user_defined, new_zealand, japan, north_carolina, eritrea, bahamas\n",
    "\n",
    "aoi_data = {\n",
    "    'user_defined': {\n",
    "        'target_date': target_date,\n",
    "        'target_rgt': target_rgt,\n",
    "        'bbox_coords': [],\n",
    "    },\n",
    "    'new_zealand': {\n",
    "        'target_date': '2022-07-05',\n",
    "        'target_rgt': 214,\n",
    "        'bbox_coords': [[[172.66, -40.63],\n",
    "                         [172.66, -40.47],\n",
    "                         [173.14, -40.47],\n",
    "                         [173.14, -40.63],\n",
    "                         [172.66, -40.63]]]\n",
    "    },\n",
    "    'japan': {\n",
    "        'target_date': '2021-10-30',\n",
    "        'target_rgt': 582,\n",
    "        'bbox_coords': [[[127.67, 26.16],\n",
    "                         [127.67, 26.77],\n",
    "                         [128.24, 26.77],\n",
    "                         [128.24, 26.16],\n",
    "                         [127.67, 26.16]]]\n",
    "    },\n",
    "    'north_carolina': {\n",
    "        'target_date': '2022-06-26',\n",
    "        'target_rgt': 65,\n",
    "        'bbox_coords': [[[-75.87, 34.82],\n",
    "                         [-75.87, 36.17],\n",
    "                         [-75.19, 36.17],\n",
    "                         [-75.19, 34.82],\n",
    "                         [-75.87, 34.82]]]\n",
    "    },\n",
    "    'eritrea': {\n",
    "        'target_date': '2022-09-19',\n",
    "        'target_rgt': 1363,\n",
    "        'bbox_coords': [[[39.90, 15.47],\n",
    "                         [39.90, 16.10],\n",
    "                         [40.53, 16.10],\n",
    "                         [40.53, 15.47],\n",
    "                         [39.90, 15.47]]]\n",
    "    },\n",
    "    'bahamas': {\n",
    "        'target_date': '2021-07-09',\n",
    "        'target_rgt': 248,\n",
    "        'bbox_coords': [[[-76.8, 23.27],\n",
    "                          [-76.8, 23.84],\n",
    "                          [-76.22, 23.84],\n",
    "                          [-76.22, 23.27],\n",
    "                          [-76.8, 23.27]]]\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    aoi_info = aoi_data[aoi_name]\n",
    "    target_date = aoi_info['target_date']\n",
    "    target_rgt = aoi_info['target_rgt']\n",
    "    bbox_coords = aoi_info['bbox_coords']\n",
    "    \n",
    "except KeyError:\n",
    "    raise RuntimeError(\"Invalid AOI name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899edfd-e63f-4c01-ba54-b12516f8ce0b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We've specified a date and ground track for our data, but many ICESat-2 passes are larger than the actual study site. So lets specify a bounding box on the map below to use when querying data to reduce the overall data quantity. If using one of the preselected AOI's, it will be shown automatically. If not, use the polygon or box drawing tools to make your own! Results are automatically saved. If you need to start over with your polygon, just rerun the cell below. It's also recommended to ensure your bounding box is primarily over water for bathymetric analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be3845-d104-468c-8aae-dddd098ab1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to store any bounds drawn by the user\n",
    "def handle_draw(target, action, geo_json):\n",
    "    if action == 'created':\n",
    "        coords = geo_json['geometry']['coordinates'][0]\n",
    "        bbox_coords.append(coords)\n",
    "\n",
    "def reverse_coordinates(bbox_coords):\n",
    "    reversed_coords = []\n",
    "    \n",
    "    for box in bbox_coords:\n",
    "        reversed_box = []\n",
    "        for point in box:\n",
    "            reversed_box.append([point[1], point[0]])\n",
    "        reversed_coords.append(reversed_box)\n",
    "    \n",
    "    return reversed_coords\n",
    "\n",
    "# setting up the map\n",
    "m = ipyleaflet.Map(basemap=ipyleaflet.basemaps.Esri.WorldImagery, \n",
    "        center=(0, 0), \n",
    "        zoom=3, \n",
    "        scroll_wheel_zoom=True)\n",
    "\n",
    "# simplifying user options - can be used to enable polygons, line drawings, etc\n",
    "dc = ipyleaflet.DrawControl(circlemarker={}, polyline={})\n",
    "\n",
    "# defining bounding box/polygon properties\n",
    "custom_shape_options = {\n",
    "        \"fillColor\": \"red\",\n",
    "        \"color\": \"red\",\n",
    "        \"fillOpacity\": 0.5\n",
    "    }\n",
    "\n",
    "dc.rectangle = {\"shapeOptions\": custom_shape_options}\n",
    "dc.polygon = {\"shapeOptions\": custom_shape_options}\n",
    "\n",
    "# add pre-existing bounding box to map if it exists\n",
    "if aoi_name == 'user_defined':\n",
    "    bbox_coords = []\n",
    "    print('Draw bounding box on map below...')\n",
    "\n",
    "else:\n",
    "    poly_gdf = gpd.GeoDataFrame(geometry=[Polygon(bbox_coords[0])],\n",
    "                                crs=\"EPSG:4326\")\n",
    "\n",
    "    m.center=(poly_gdf.geometry[0].centroid.y, poly_gdf.geometry[0].centroid.x)\n",
    "    m.zoom = 8\n",
    "\n",
    "    poly_map = ipyleaflet.Polygon(\n",
    "        locations=reverse_coordinates(bbox_coords),\n",
    "        color=\"red\",\n",
    "        fill_color=\"red\"\n",
    "    )\n",
    "\n",
    "    m.add_layer(poly_map);\n",
    "    \n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d289a0-825a-4a50-8a39-fa578011a93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the extracted information\n",
    "print('AOI Name:', aoi_name.upper())\n",
    "print(\"Target Date:\", target_date)\n",
    "print(\"Target RGT:\", target_rgt)\n",
    "print(\"Bounding Box Coordinates:\\n\", np.round(bbox_coords, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66a53f-a46b-4feb-87a0-39003ab932cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the middle, strong beam for this demo\n",
    "# for more on this, see the ATL03 user guide, or other hackweek documentation\n",
    "beam_type = 'strong'\n",
    "track_num = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb795f76-1fa1-4636-ad8f-60cd6c865f26",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Downloading ICESat-2 Data\n",
    "\n",
    "Now that we've specified a bounding box, date, and ground track, we can use Sliderule to download the photon data. Note that we are also specially requesting additional fields from the ATL03 data needed for bathymetric analysis (e.g., ref_azimuth). The data dictionary, which contains details of all available fields is available via NSIDC [(link to PDF)](https://nsidc.org/sites/default/files/documents/technical-reference/icesat2_atl03_data_dict_v006.pdf).\n",
    "\n",
    "Note that there are a many ways to access photon data - using EarthData, OpenAltimetry, NSIDC, icepyx, etc... the best really depends on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605d245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Reformatting bounding box for query purposes\n",
    "coords_arr = np.array(bbox_coords[0]) # use only the first polygon you draw\n",
    "poly = []\n",
    "\n",
    "for point in coords_arr:\n",
    "    poly.append({\n",
    "        'lat': point[1],\n",
    "        'lon': point[0]\n",
    "    })\n",
    "\n",
    "# sliderule parameters for querying photon data\n",
    "parms = {\n",
    "    \n",
    "    \"len\": 20,\n",
    "    \"pass_invalid\": True, # include segments which dont pass all checks\n",
    "    \"cnf\": -2, # returns all photons\n",
    "    \n",
    "    #  try other signal confidence scores! SRT_LAND, SRT_OCEAN, SRT_SEA_ICE, SRT_LAND_ICE, SRT_INLAND_WATER\n",
    "    \"srt\": icesat2.SRT_LAND, \n",
    "    \n",
    "    # density based signal finding\n",
    "    \"yapc\": dict(knn=0, win_h=6, win_x=11, min_ph=4, score=0), \n",
    "    \n",
    "    # extra fields from ATL03 gtxx/geolocation or gtxx/geophys_corr channels\n",
    "    \"atl03_geo_fields\": [\"ref_azimuth\", \"ref_elev\", \"geoid\"],\n",
    "    \n",
    "    # extra fields via ATL03 \"gtxx/heights\" (see atl03 data dictionary)\n",
    "    \"atl03_ph_fields\": [], # \n",
    "    \n",
    "    # add query polygon\n",
    "    \"poly\": poly,\n",
    "\n",
    "}\n",
    "\n",
    "# Formatting datetime query for demo purposes - 1 day buffer\n",
    "day_window = 1 # days on either side to query\n",
    "target_dt = datetime.strptime(target_date, '%Y-%m-%d')\n",
    "time_start = target_dt - timedelta(days=day_window)\n",
    "time_end = target_dt + timedelta(days=day_window)\n",
    "\n",
    "# find granule for each region of interest\n",
    "granules_list = earthdata.cmr(short_name='ATL03', \n",
    "                              polygon=poly, \n",
    "                              time_start=time_start.strftime('%Y-%m-%d'), \n",
    "                              time_end=time_end.strftime('%Y-%m-%d'), \n",
    "                              version='006')\n",
    "\n",
    "print(granules_list)\n",
    "\n",
    "# create an empty geodataframe\n",
    "df_0 = icesat2.atl03sp(parms, asset=asset, version='006', resources=granules_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c90b1-579a-4f4e-a6ab-0c41c1195963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confirm that we got extra fields from ATL03 for each photon\n",
    "print(f'Available photon-rate features: \\n{df_0.columns.values}\\n')\n",
    "\n",
    "# inspect photon dataframe\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6f5b5-08f0-45ff-8d8d-ab392d653a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reducing the total photon data down to a single beam for demonstration purposes\n",
    "# from the Grand Mesa SlideRule Example\n",
    "\n",
    "def reduce_dataframe(gdf, RGT=None, GT=None, track=None, pair=None, cycle=None, beam='', crs=4326):\n",
    "    # convert coordinate reference system\n",
    "    df = gdf.to_crs(crs)\n",
    "    \n",
    "    # reduce to reference ground track\n",
    "    if RGT is not None:\n",
    "        df = df[df[\"rgt\"] == RGT]\n",
    "        \n",
    "    # reduce to ground track (gt[123][lr]), track ([123]), or pair (l=0, r=1) \n",
    "    gtlookup = {icesat2.GT1L: 1, icesat2.GT1R: 1, icesat2.GT2L: 2, icesat2.GT2R: 2, icesat2.GT3L: 3, icesat2.GT3R: 3}\n",
    "    \n",
    "    pairlookup = {icesat2.GT1L: 0, icesat2.GT1R: 1, icesat2.GT2L: 0, icesat2.GT2R: 1, icesat2.GT3L: 0, icesat2.GT3R: 1}\n",
    "    \n",
    "    if GT is not None:\n",
    "        df = df[(df[\"track\"] == gtlookup[GT]) & (df[\"pair\"] == pairlookup[GT])]\n",
    "    if track is not None:\n",
    "        df = df[df[\"track\"] == track]\n",
    "    if pair is not None:\n",
    "        df = df[df[\"pair\"] == pair]\n",
    "        \n",
    "    # reduce to weak or strong beams\n",
    "    # tested on cycle 11, where the strong beam in the pair matches the spacecraft orientation.\n",
    "    # Need to check on other cycles\n",
    "    if (beam == 'strong'):\n",
    "        df = df[df['sc_orient'] == df['pair']]\n",
    "    elif (beam == 'weak'):\n",
    "        df = df[df['sc_orient'] != df['pair']]\n",
    "        \n",
    "    # reduce to cycle\n",
    "    if cycle is not None:\n",
    "        df = df[df[\"cycle\"] == cycle]\n",
    "        \n",
    "    # otherwise, return both beams\n",
    "    return df\n",
    "\n",
    "df = reduce_dataframe(df_0, \n",
    "                      RGT=target_rgt, \n",
    "                      track=track_num, \n",
    "                      beam=beam_type, \n",
    "                      crs='EPSG:4326')\n",
    "\n",
    "# add a column for along-track distance\n",
    "df['along_track_meters'] = df['segment_dist']+df['distance']-np.min(df['segment_dist'])\n",
    "\n",
    "# compute orthometric heights using the onboard geoid model (EGM08)\n",
    "df['height_ortho'] = df['height'] - df['geoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5cdd9-b66d-4f7e-a067-c5f479f22970",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Let's visualize the ICESat-2 overpass on our map to get a better sense of what we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e80cff-9efe-4d0b-86f0-c07034fc62e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get location of every 100th photon (to reduce data load)\n",
    "ph_lon = df.geometry.x.values[::100]\n",
    "ph_lat = df.geometry.y.values[::100]\n",
    "ph_loc_list = [[y, x] for x, y in zip(ph_lon, ph_lat)]\n",
    "\n",
    "ground_track = ipyleaflet.Polyline(locations=ph_loc_list, \n",
    "                         color='limegreen', weight=5)\n",
    "\n",
    "m.add_layer(ground_track)\n",
    "\n",
    "# see map above has been updated with the satellite ground track!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ea134-0353-4236-967c-7741c61a718f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elevation range for plotting\n",
    "ylim = [-25, 10]\n",
    "\n",
    "# filter very shallow / deep data to refine bathymetry\n",
    "min_bathy_depth = 0.5 \n",
    "max_bathy_depth = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3fc90-f6dd-4973-831e-224bd445949f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Visualize Signal \n",
    "The ATL03 product and Sliderule provide several built-in measures of photon signal. We've imported the 'Land Confidence' photon signal flag, but this doesn't always capture bathymetry as we'd expect, and is only computed within a certain distance nearshore. We also have a quality flag, which is meant to detect possible artifacts in the data due to instrument effects. For bathymetry, we're most interested in afterpulse/TEP returns which can appear as false signal below a bright water surface, tripping up many bathymetry extraction approaches. Lastly, we'll inspect YAPC, a density-based algorithm for signal detection that can be queried using sliderule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45661328-31c3-4d61-a231-eecf3e8e4a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create figure and axes\n",
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "####################################\n",
    "# ATL03 signal confidence plot\n",
    "colors = {-1:['yellow', 'not_considered'],\n",
    "          0:['grey', 'noise'],  \n",
    "          1:['red', 'buffer'],\n",
    "          2:['green','low_conf'],\n",
    "          3:['blue','med_conf'],\n",
    "          4:['black', 'high_conf']}\n",
    "\n",
    "for class_val, color_name in colors.items():\n",
    "    ii = df['atl03_cnf']==class_val\n",
    "    axs[0].plot(df['along_track_meters'][ii], df['height_ortho'][ii],\n",
    "               'o', markersize=1, alpha=0.3, color=color_name[0], \n",
    "               label=color_name[1])\n",
    "               \n",
    "axs[0].legend(loc=3, frameon=True, markerscale=5)\n",
    "axs[0].set_xlabel('x_ATC, m')\n",
    "axs[0].set_ylabel('height, m')  \n",
    "axs[0].set_title('ATL03 classification')\n",
    "\n",
    "####################################\n",
    "# YAPC density based confidence plot\n",
    "ii = np.argsort(df['yapc_score'])\n",
    "sc = axs[1].scatter(df['along_track_meters'][ii], df['height_ortho'][ii], \n",
    "               2, c=df['yapc_score'][ii], vmin=10, vmax=255, cmap='plasma_r')\n",
    "axs[1].set_ylim(ylim)\n",
    "axs[1].set_ylabel('height, m')\n",
    "axs[1].set_title('YAPC score')\n",
    "\n",
    "# Add inset axes for colorbar\n",
    "cax = inset_axes(axs[1], width=\"2%\", height=\"90%\", loc=2)\n",
    "\n",
    "# Add colorbar to inset axes    \n",
    "cbar = fig.colorbar(sc, cax=cax, orientation='vertical')  \n",
    "\n",
    "####################################\n",
    "# Quality Photon Flag\n",
    "colors = {0:['black', 'nominal'], \n",
    "          1:['red', 'possible_afterpulse'],\n",
    "          2:['green','possible_impulse_response_effect']}\n",
    "\n",
    "for class_val, color_name in colors.items():\n",
    "    ii = df['quality_ph']==class_val\n",
    "    if class_val==0:\n",
    "        axs[2].plot(df['along_track_meters'][ii], df['height_ortho'][ii],\n",
    "                    'o', markersize=.5, alpha=0.3, color=color_name[0], \n",
    "                    label=color_name[1])\n",
    "    else:\n",
    "        axs[2].plot(df['along_track_meters'][ii], df['height_ortho'][ii],\n",
    "                    'o', markersize=1, alpha=1, color=color_name[0],\n",
    "                    label=color_name[1])\n",
    "\n",
    "axs[2].legend(loc=3, frameon=True, markerscale=5)\n",
    "axs[2].set_ylabel('height, m')  \n",
    "axs[2].set_title('Photon classification')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim(ylim)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e72f8-cc2f-4988-8c5f-de1451effcbb",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We'll use YAPC to filter signal photons for this demo. Specify a manual value by inspection of the data above, or try an automated approach like Otsu Thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a37aac-384f-4c5a-9515-da3405ea3622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yapc_threshold = skimage.filters.threshold_otsu(df['yapc_score'])\n",
    "# plt.hist(df['yapc_score'])\n",
    "# plt.axvline(yapc_threshold)\n",
    "\n",
    "yapc_threshold = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb105b0-467f-40bc-a6b7-d28c4e55d665",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Preprocess Data\n",
    "First, let remove any noise / land photons from the data. Then, let's start to extract water surface and seafloor from the photon data. There are several approaches for this in the literature, but we'll focus on a generalizable, expandable method of histogramming the photon data at a specified resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d33aa-dd5d-408f-98eb-f99371f1904c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get photons with a minimum YAPC signal score \n",
    "signal_photons_yapc = df['yapc_score'] > yapc_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c835c4-c7bc-478b-aeb8-95b31b1f6d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# manually specify a water surface elevation and remove any land photons higher than that\n",
    "# trim_photons_above = 5 # meters, orthometric height\n",
    "\n",
    "# alternatively, if your track is mostly water, you can estimate the water surface as the most common photon elevation value\n",
    "bin_edges_1 = np.arange(-50, 50, 0.1)\n",
    "hist_1 = plt.hist(df['height_ortho'][signal_photons_yapc], bins=bin_edges_1)[0]\n",
    "\n",
    "trim_photons_above = bin_edges_1[np.argmax(hist_1)] + 1 # buffer in meters for surface width / waves\n",
    "\n",
    "plt.axvline(trim_photons_above, color='k')\n",
    "plt.xlabel('Orthometric height (m)')\n",
    "plt.ylabel('Count')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4ba25-2bca-455c-8ee0-091ed556ca56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dataframe of signal only\n",
    "water_zone_photons = df['height_ortho'] < trim_photons_above\n",
    "df_cleaned = df.loc[water_zone_photons & signal_photons_yapc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56afd57-20b5-431c-96eb-4881bbd038c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_z = 0.1 # height resolution\n",
    "res_at = 20 # along track resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2647bf7-5a88-458f-81c3-3bbf3b697be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define along track bin sizing\n",
    "\n",
    "bin_edges_z = np.arange(ylim[0], ylim[1], res_z)\n",
    "\n",
    "range_at = [0, #df_cleaned.along_track_meters.min(), \n",
    "            df_cleaned.along_track_meters.max() + res_at]\n",
    "\n",
    "bin_edges_at = np.arange(range_at[0], range_at[1], res_at)\n",
    "\n",
    "bin_centers_z = bin_edges_z[:-1] + np.diff(bin_edges_z)[0] / 2\n",
    "\n",
    "bin_centers_at = bin_edges_at[:-1] + np.diff(bin_edges_at)[0] / 2\n",
    "\n",
    "hist_2 = np.histogram2d(df_cleaned.along_track_meters, df_cleaned.height_ortho,\n",
    "               bins = [bin_edges_at, bin_edges_z])[0]\n",
    "\n",
    "hist_2 = hist_2.T # more intuitive orientation\n",
    "\n",
    "# using a gaussian filter allows us to use finer binning resolution\n",
    "sigma_at = 50 / res_at\n",
    "hist_2 = scipy.ndimage.gaussian_filter1d(hist_2, sigma_at, axis=1)\n",
    "\n",
    "sigma_z = .2 / res_z\n",
    "hist_2 = scipy.ndimage.gaussian_filter1d(hist_2, sigma_z, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b4818-3761-4cb4-8380-d257fbb9a89a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Inspect Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc5688-847c-4f9f-a762-39f7b4417046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 1, figsize=(8, 5), sharex=True)\n",
    "\n",
    "# plot the photon data\n",
    "ax[0].plot(df['along_track_meters'],\n",
    "    df['height_ortho'], '.', c='grey', markersize=1, alpha=0.5, label='All Photons')\n",
    "ax[0].plot(df_cleaned['along_track_meters'],\n",
    "    df_cleaned['height_ortho'], 'r.', markersize=1, alpha=0.5, label='Signal Photons')\n",
    "ax[0].set_ylim(ylim)\n",
    "ax[0].set_ylabel('height, m')\n",
    "ax[0].set_xlabel('$x_{ATC}$, m');\n",
    "ax[0].set_title('Esimate of Water Signal')\n",
    "ax[0].legend(markerscale=5)\n",
    "\n",
    "# plot the histogrammed data\n",
    "orig = ax[1].imshow(hist_2, norm='log',\n",
    "           vmin=1e-2, vmax=10, # colormap bounds\n",
    "           cmap='viridis',\n",
    "           origin='lower',\n",
    "           interpolation_stage = 'rgba',\n",
    "           extent=[bin_edges_at[0], bin_edges_at[-1], \n",
    "                   bin_edges_z[0], bin_edges_z[-1]], \n",
    "           aspect='auto')\n",
    "\n",
    "ax[1].set_ylabel('height, m')\n",
    "# f.colorbar(orig, ax=ax[1], label='Count')\n",
    "ax[1].set_title('Binned Photon Data');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9651cf87-9b09-4010-ac15-719d78bb98da",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "We'll look at our data in vertical histograms akin to lidar waveforms from other platforms like GEDI. The following cell provides some insight into what this track looks like from this point of view by plotting several points along-track, but it isn't required for the actual analysis. Can you spot the water surface and any seafloor returns in the waveforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb74a95-d6b4-4f44-8d2b-5c4981c3fc05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "n_inspection_points = 6 # automatically choose equally spaced locations to inspect\n",
    "\n",
    "inspect_along_track_locations = np.linspace(bin_centers_at[0], bin_centers_at[-1], \n",
    "                                            n_inspection_points + 2, # adjust for edges\n",
    "                                            dtype=np.int64)[1:-1] \n",
    "\n",
    "# round \n",
    "inspect_along_track_locations = np.round(inspect_along_track_locations, -3)\n",
    "\n",
    "# inspect_along_track_locations = [5e3] # manually choose locations to inspect\n",
    "\n",
    "kernel_size_meters = .5\n",
    "\n",
    "### plotting\n",
    "\n",
    "kernel_size = np.int64(kernel_size_meters / res_z)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(inspect_along_track_locations), figsize=(8,5), sharey=True)\n",
    "\n",
    "if len(inspect_along_track_locations) == 1:\n",
    "    \n",
    "    axes = [axes]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "        \n",
    "    along_track_location_i = inspect_along_track_locations[i]\n",
    "    \n",
    "    waveform = hist_2[:, np.int64(along_track_location_i/res_at)]\n",
    "    \n",
    "    waveform_smoothed = np.convolve(waveform, np.ones(kernel_size)/kernel_size, mode='same')\n",
    "\n",
    "    ax.plot(waveform, bin_centers_z, c='grey', alpha=.5, label='Binned Photon Data')\n",
    "    \n",
    "    ax.plot(waveform_smoothed, bin_centers_z, c='r', label='Smoothed Waveform')\n",
    "    \n",
    "    ax.set_title(f'{np.int64(along_track_location_i)}m')\n",
    "    \n",
    "    # ax.set_xscale('log')\n",
    "\n",
    "\n",
    "fig.supylabel('Elevation (m)')\n",
    "fig.supxlabel('Photon Count')\n",
    "fig.suptitle('Sample Waveforms From Along-track Locations')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4190f45-eedf-41d6-aaa2-f799fff803b2",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Refraction Corrected Bathymetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1af1c-815d-4092-ad67-a34c31785368",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "First, lets create a function for identifying water surface and seafloor returns from the binned data. We find the peaks from each individual waveform, and assume the topmost return is the most likely water surface. From the remaining peaks, we'll select the most prominent peak as bathymetry. We use peak prominence instead of peak heights in order to minimize issues caused by turbidity in the water column. We'll also use height and prominence requirements on the signal peaks specifically tuned for the preprocessing steps defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0eee23-f572-43d6-b135-46c68c2a5c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_bathymetry(waveform, min_height=.25, min_prominence=.25):\n",
    "    \"\"\"\n",
    "    Extracts bathymetry information from a histogram of photon heights and simple assumptions of topographic features.\n",
    "\n",
    "    Parameters:\n",
    "    waveform (1D array-like): Input histogram of photon heights.\n",
    "    min_height (float, optional): Minimum height of peaks to be considered for bathymetry or water surface.\n",
    "                                  Defaults to 0.25.\n",
    "    min_prominence (float, optional): Minimum prominence of peaks to be considered for bathymetry or water surface.\n",
    "                                      Defaults to 0.25.\n",
    "\n",
    "    Returns:\n",
    "    water_surface_peak (int or None): Index of the peak representing the water surface, or None if no valid peaks are found.\n",
    "    bathy_peak (int or None): Index of the peak representing the subsurface bathymetry, or None if no valid peaks are found.\n",
    "\n",
    "    Notes:\n",
    "    Input data should be preprocessed to remove as much background noise, land, or vegetation returns as possible.\n",
    "    \n",
    "    Author: Jonathan Markel, UT Austin\n",
    "    Date: 08/2023\n",
    "\n",
    "    \"\"\"    \n",
    "    peaks, peak_info_dict = scipy.signal.find_peaks(waveform, \n",
    "                          height=min_height, \n",
    "                          prominence=min_prominence)\n",
    "        \n",
    "    if len(peaks) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # topmost return is the water surface\n",
    "    water_surface_peak = peaks[-1]\n",
    "    \n",
    "    # all other peaks are possible bathymetry\n",
    "    bathy_candidate_peaks = peaks[:-1]\n",
    "    \n",
    "    bathy_candidate_peak_heights = peak_info_dict['peak_heights'][:-1]\n",
    "    bathy_candidate_peak_prominences = peak_info_dict['prominences'][:-1]\n",
    "    \n",
    "    if len(bathy_candidate_peaks) == 0:\n",
    "        return water_surface_peak, None\n",
    "        \n",
    "    # get the most prominent subsurface peak\n",
    "    bathy_peak = bathy_candidate_peaks[np.argmax(bathy_candidate_peak_prominences)]\n",
    "    \n",
    "    return water_surface_peak, bathy_peak\n",
    "    \n",
    "\n",
    "surface_idx, bathy_idx = extract_bathymetry(waveform_smoothed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da6e9a-4cf8-4288-946a-dec283128c0c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We'll also define a refraction correction function to account for speed of light difference between air and water, as well as the satellite pointing angle. This function is derived from the Parrish, et al. 2019 paper, [Validation of ICESat-2 ATLAS Bathymetry and Analysis of ATLAS’s Bathymetric Mapping Performance](https://www.mdpi.com/2072-4292/11/14/1634). A Matlab implementation is also available [here](https://github.com/ICESat2-Bathymetry/Information/tree/main/code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1aafb-991b-476b-b102-ab8d60822446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def photon_refraction(W, Z, ref_az, ref_el,\n",
    "                      n1=1.00029, n2=1.34116):\n",
    "    '''\n",
    "    ICESat-2 refraction correction implented as outlined in Parrish, et al. \n",
    "    2019 for correcting photon depth data.\n",
    "\n",
    "    Highly recommended to reference elevations to geoid datum to remove sea\n",
    "    surface variations.\n",
    "\n",
    "    https://www.mdpi.com/2072-4292/11/14/1634\n",
    "\n",
    "    Author: \n",
    "    Jonathan Markel\n",
    "    Graduate Research Assistant\n",
    "    3D Geospatial Laboratory\n",
    "    The University of Texas at Austin\n",
    "    jonathanmarkel@gmail.com\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : float, or nx1 array of float\n",
    "        Elevation of the water surface.\n",
    "\n",
    "    Z : nx1 array of float\n",
    "        Elevation of seabed photon data. Highly recommend use of geoid heights.\n",
    "\n",
    "    ref_az : nx1 array of float\n",
    "        Photon-rate reference photon azimuth data. Should be pulled from ATL03\n",
    "        data parameter 'ref_azimuth'. Must be same size as seabed Z array.\n",
    "\n",
    "    ref_el : nx1 array of float\n",
    "        Photon-rate reference photon azimuth data. Should be pulled from ATL03\n",
    "        data parameter 'ref_elev'. Must be same size as seabed Z array.\n",
    "\n",
    "    n1 : float, optional\n",
    "        Refractive index of air. The default is 1.00029.\n",
    "\n",
    "    n2 : float, optional\n",
    "        Refractive index of water. Recommended to use 1.34116 for saltwater \n",
    "        and 1.33469 for freshwater. The default is 1.34116.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dE : nx1 array of float\n",
    "        Easting offset of seabed photons.\n",
    "\n",
    "    dN : nx1 array of float\n",
    "        Northing offset of seabed photons.\n",
    "\n",
    "    dZ : nx1 array of float\n",
    "        Vertical offset of seabed photons.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # compute uncorrected depths\n",
    "    D = W - Z\n",
    "    H = 496  # mean orbital altitude of IS2, km\n",
    "    Re = 6371  # mean radius of Earth, km\n",
    "\n",
    "    # angle of incidence (wout Earth curvature)\n",
    "    theta_1_ = (np.pi / 2) - ref_el\n",
    "\n",
    "    # # ignoring curvature correction based on correspondence with the author\n",
    "    # # incidence correction for earths curvature - eq 13\n",
    "    # delta_theta_EC = np.arctan(H * np.tan(theta_1_) / Re)\n",
    "\n",
    "    # angle of incidence\n",
    "    theta_1 = theta_1_ # + delta_theta_EC\n",
    "\n",
    "    # angle of refraction\n",
    "    theta_2 = np.arcsin(n1 * np.sin(theta_1) / n2)  # eq 1\n",
    "\n",
    "    phi = theta_1 - theta_2\n",
    "\n",
    "    # uncorrected slant range to the uncorrected seabed photon location\n",
    "    S = D / np.cos(theta_1)  # eq 3\n",
    "\n",
    "    # corrected slant range\n",
    "    R = S * n1 / n2  # eq 2\n",
    "\n",
    "    P = np.sqrt(R**2 + S**2 - 2*R*S*np.cos(theta_1 - theta_2))  # eq 6\n",
    "\n",
    "    gamma = (np.pi / 2) - theta_1  # eq 4\n",
    "\n",
    "    alpha = np.arcsin(R * np.sin(phi) / P)  # eq 5\n",
    "\n",
    "    beta = gamma - alpha  # eq 7\n",
    "\n",
    "    # cross-track offset\n",
    "    dY = P * np.cos(beta)  # eq 8\n",
    "\n",
    "    # vertical offset\n",
    "    dZ = P * np.sin(beta)  # eq 9\n",
    "\n",
    "    kappa = ref_az\n",
    "\n",
    "    # UTM offsets\n",
    "    dE = dY * np.sin(kappa)  # eq 10\n",
    "    dN = dY * np.cos(kappa)  # eq 11\n",
    "\n",
    "    return dE, dN, dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40038b54-aaff-49be-b119-34e36239a15b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Finally, we'll loop through each waveform, extract surfaces, compute refraction corrections, and store the resulting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c786d9b-d19c-4393-b037-16127576c4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up storage for binned and photon bathymetry data\n",
    "water_surface = np.nan * np.ones_like(bin_centers_at) # elevation, EGM08\n",
    "bathymetry_uncorrected = np.nan * np.ones_like(bin_centers_at)\n",
    "bathymetry_corrected = np.nan * np.ones_like(bin_centers_at)\n",
    "bin_centroid = np.empty_like(bin_centers_at, dtype=shapely.Point) # location of bin in lat / lon\n",
    "df_cleaned['dz_refraction'] = 0 # refraction correction\n",
    "\n",
    "# for each location along track (with a progress bar)\n",
    "for i_at in tqdm(range(len(bin_centers_at))):\n",
    "    \n",
    "    waveform_i = hist_2[:, i_at]\n",
    "        \n",
    "    # 1. ESTIMATE WATER/SEAFLOOR SURFACES\n",
    "    surface_idx, bathy_idx = extract_bathymetry(waveform_i, \n",
    "                                                min_height=0.1, \n",
    "                                                min_prominence=0.1)\n",
    "\n",
    "    if surface_idx is None:\n",
    "        continue \n",
    "        \n",
    "    # get the actual elevation\n",
    "    water_surface_z = bin_centers_z[surface_idx]\n",
    "    water_surface[i_at] = water_surface_z\n",
    "            \n",
    "    # 2. REFRACTION CORRECT PHOTON HEIGHTS\n",
    "            \n",
    "    # index subsurface photons in this along-track bin\n",
    "    ph_refr_i = (df_cleaned.along_track_meters.values >= bin_centers_at[i_at] - res_at / 2) & \\\n",
    "                (df_cleaned.along_track_meters.values <= bin_centers_at[i_at] + res_at / 2) & \\\n",
    "                (df_cleaned.height_ortho.values <= (water_surface_z))\n",
    "    \n",
    "    # no photons in this bin\n",
    "    if np.sum(ph_refr_i) == 0:\n",
    "        continue\n",
    "    \n",
    "    z_ph_i = df_cleaned.height_ortho.values[ph_refr_i]\n",
    "    ref_az_ph_i = df_cleaned.ref_azimuth.values[ph_refr_i]\n",
    "    ref_elev_ph_i = df_cleaned.ref_elev.values[ph_refr_i]\n",
    "    \n",
    "    # compute refraction corrections for all subsurface photons\n",
    "    _, _, dz_ph_i = photon_refraction(water_surface_z, \n",
    "                                   z_ph_i, ref_az_ph_i, ref_elev_ph_i, \n",
    "                                   n1=1.00029, n2=1.34116)\n",
    "    \n",
    "    df_cleaned.loc[ph_refr_i, 'dz_refraction'] = dz_ph_i\n",
    "    \n",
    "    # compute refraction correction for modeled bathymetry return\n",
    "    if bathy_idx is None:\n",
    "        continue        \n",
    "        \n",
    "    bathymetry_uncorrected_i = bin_centers_z[bathy_idx]\n",
    "                        \n",
    "    ref_az_bin_i = np.mean(ref_az_ph_i)\n",
    "    ref_elev_bin_i = np.mean(ref_elev_ph_i)\n",
    "    _, _, dz_bin_i = photon_refraction(water_surface_z, \n",
    "                               bathymetry_uncorrected_i, \n",
    "                                       ref_az_bin_i, ref_elev_bin_i, \n",
    "                               n1=1.00029, n2=1.34116)\n",
    "    \n",
    "    bathymetry_corrected_i = bathymetry_uncorrected_i + dz_bin_i\n",
    "    \n",
    "    # filter likely erroneous signal caused by wave / turbidity \n",
    "    \n",
    "    if (water_surface_z - bathymetry_corrected_i) < min_bathy_depth:\n",
    "        continue\n",
    "        \n",
    "    elif (water_surface_z - bathymetry_corrected_i) > max_bathy_depth:\n",
    "        continue\n",
    "\n",
    "    bathymetry_uncorrected[i_at] = bathymetry_uncorrected_i\n",
    "    bathymetry_corrected[i_at] = bathymetry_corrected_i\n",
    "    \n",
    "    # geolocate this bin\n",
    "    bin_centroid[i_at] = df_cleaned.loc[ph_refr_i, 'geometry'].unary_union.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4d328-47fb-4c87-8da6-8b10cf634966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 5))\n",
    "\n",
    "# # unrefracted photon elevations\n",
    "plt.plot(df.along_track_meters, df.height_ortho, '.',\n",
    "        c='grey', markersize=1, alpha=0.5, label='Uncorrected Photons')\n",
    "\n",
    "plt.plot(df_cleaned.along_track_meters, df_cleaned.height_ortho + df_cleaned.dz_refraction, 'k.',\n",
    "        markersize=1, alpha=0.5, label='Refraction Corrected Photon Data')\n",
    "\n",
    "plt.plot(bin_centers_at, water_surface, 'b.', \n",
    "         markersize=2, alpha=1, label='Estimated Water Surface')\n",
    "\n",
    "plt.plot(bin_centers_at, bathymetry_corrected, 'r-', \n",
    "          markersize=1, alpha=0.9, label='Estimated Seafloor')\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Corrected Heights, m')\n",
    "plt.xlabel('$x_{ATC}$, m');\n",
    "plt.ylim(ylim)\n",
    "plt.xlim([0e3, 10e3])\n",
    "plt.title('Refraction Corrected Bathymetry');\n",
    "plt.legend(markerscale=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d2fca-2d48-445b-a342-b8e7ff5447d7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a5297-b709-4add-910f-390df4041ef0",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Let's organize our bathymetry data into a GeoDataFrame for visualization and exporting to other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34015451-9883-4bd8-ba3f-5b668a68caad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_data = ~np.isnan(bathymetry_corrected)\n",
    "\n",
    "df_out = gpd.GeoDataFrame(np.vstack([water_surface[good_data], \n",
    "                                     bathymetry_corrected[good_data]]).T, \n",
    "                 columns=['water_surface_z', 'bathymetry_corr_z'], \n",
    "                 geometry=bin_centroid[good_data], \n",
    "                 crs=df_cleaned.crs)\n",
    "\n",
    "df_out['depth'] = df_out.water_surface_z - df_out.bathymetry_corr_z\n",
    "\n",
    "df_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03e4e4-3248-425a-a087-8c27a9f76647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inspect data on an interactive map\n",
    "plot_color_depth = df_out.depth.quantile(0.99) # percentile defines maximum depth for colormap\n",
    "\n",
    "# sort for better color visibilty when plotting\n",
    "df_vis = df_out.sort_values('bathymetry_corr_z', ascending=False)\n",
    "\n",
    "df_vis.explore(tiles='Esri.WorldImagery', \n",
    "                 column='depth', \n",
    "                 cmap='inferno_r', \n",
    "                 vmax=plot_color_depth,        # minimum depth for plotting color\n",
    "                 vmin=min_bathy_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d13ab5b-7132-4409-a36d-8ebace17dc76",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Now that our data is organized as a GeoDataFrame, we can utilize any of the many built in tools for saving to different filetypes. [For more, see GeoPandas documentation here](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.to_file.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ad20f-99ea-4528-a4b5-c8e39bf3d5af",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Congrats! You're now able to compute refraction corrected bathymetry from ICESat-2 photon data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f03306-0955-44f6-a59a-1c97ff3976e8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Helpful Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615955d8-d27f-4dbc-85a5-5c87e33a4d69",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "- [ICESat-2 Bathymetry Working Group Information Repository](https://github.com/ICESat2-Bathymetry/Information)\n",
    "- [C-SHELPH Bathymetric Photon Classification - Github](https://github.com/nmt28/C-SHELPh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e860c-7516-4c4e-a677-ffa29bcdfc5f",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Contact Information\n",
    "Get in touch!\n",
    "\n",
    "**Jonathan Markel**<br>\n",
    "PhD Student<br>\n",
    "3D Geospatial Laboratory<br>\n",
    "The University of Texas at Austin<br>\n",
    "jonathanmarkel@gmail.com<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
